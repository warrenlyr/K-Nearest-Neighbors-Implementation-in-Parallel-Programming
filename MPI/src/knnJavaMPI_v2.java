/*
 * -------------------------------------------------------------------------------------------------
 * testMPI.java
 * Term: Autumn 2022
 * Class: CSS 534 â€“ Parallel Programming In Grid And Cloud
 * HW: Program 5 - Final Project
 * Author: Warren Liu
 * Date: 12/03/2022
 * -------------------------------------------------------------------------------------------------
 * KNN Graph in parallel programming.
 * Part 1: Parallel in MPI.
 * Version 2, changed knn algorithm and input file structure.
 */

import mpi.*;
import java.io.*;
import java.util.*;
import java.lang.Math;
import java.sql.Timestamp;


class knnJavaMPI_v2{

    /*
        Class to store global variables.
        Java is annoying!
    */
    public static class Global {
        // Basic variable
        public static int MASTER = 0;
        public static boolean PRINT_INFO = false;

        // MPI Tag - Send - Sizes
        public static int MPI_TAG_SEND_TEST_GROUP_SIZE = 101;
        public static int MPI_TAG_SEND_TRAIN_GROUP_SIZE = 102;
        public static int MPI_TAG_SEND_CHUNK_SIZE = 103;
        //MPI Tag - Send - Data
        public static int MPI_TAG_SEND_TEST_GROUP = 201;
        public static int MPI_TAG_SEND_TRAIN_GROUP = 202;
        // MPI Tag - Receive - Data
        public static int MPI_TAG_SEND_BACK_TOP_K = 301;

    }


    /*
        Class Node: to store every knn node.
    */
    public static class Node implements Serializable, Comparable<Node>{
        // Coordinates
        double x;
        double y;
        double z;
        // Class name
        String className;
        String newClassName;
        // This node's distance to target node
        double distance_to_target;

        public Node(){
            x = 0.0;
            y = 0.0;
            z = 0.0;
            className = "";
            distance_to_target = 0.0;
        }

        public Node(double x, double y, double z, String className){
            this.x = x;
            this.y = y;
            this.z = z;
            this.className = className;
            this.newClassName = "";
            this.distance_to_target = 0.0;
        }

        public Node(double x, double y, double z, String className, double distance_to_target){
            this.x = x;
            this.y = y;
            this.z = z;
            this.className = className;
            this.newClassName = "";
            this.distance_to_target = distance_to_target;
        }


        // Get current node's distance to target node
        public double getDistance(){
            return this.distance_to_target;
        }


        // Get current node class name
        public String getClassName(){
            return this.className;
        }


        // Helper function for debug
        public String getResultForValidation(){
            return (this.x + "," + this.y + "," + this.x + "," + this.newClassName);
        }


        // Set current node's new class name
        public void setNewClassName(String newClassName){
            this.newClassName = newClassName;
        }


        // Helper function for printing node details
        @Override
        public String toString(){
            return ("Node [x=" + this.x + ", y=" + this.y + ", z=" + this.z + 
            ", class=" + this.className + ", newClass=" + this.newClassName + ", distance=" + this.distance_to_target + "]");
        }


        // Customized compare, for treeMap use
        @Override
        public int compareTo(Node node){
            return (int) (this.distance_to_target - node.getDistance());
        }
    }


    /*
     * Class to evaluate the result generated by KNN.
     * For each node in the target(test) group, if its new class name
     * is equal to its original class name, we say the prediction
     * is correct. Otherwise, the prediction is wrong.
     * The correctness is calculated by: 
     * correct# / (correct# + wrong#)
     * 
     * @param Node[] nodeArr: A 1D node array, contains the all target(test) nodes.
     * 
     * @return double correctness.
     */
    public static double evaluateKnnCorrectness(Node[] nodeArr){
        double correct_count = 0.0;
        double wrong_count = 0.0;

        for(int i = 0; i < nodeArr.length; i ++){
            // System.out.println(nodeArr[i].newClassName + " " + nodeArr[i].className);

            if(nodeArr[i].newClassName.equals(nodeArr[i].className)){
                correct_count += 1.0;
            }
            else{
                wrong_count += 1.0;
            }
        }

        return (correct_count / (correct_count + wrong_count));
    }


    /* Function to calculate the Euclidean Distance between two nodes.
     * 
     * @param Node a: the first node.
     * @param Node b: the second node.
     * 
     * @Return double distance: the Euclidean Distance between two nodes.
     */
    public static double distance(Node a, Node b){
        double x = a.x - b.x;
        double y = a.y - b.y;
        double z = a.z - b.z;
        return Math.sqrt(x*x + y*y + z*z);
    }


    /*
     * Helper function to sort Node array by nodes' distance_to_target.
     */
    public static class SortByNodeDistance implements Comparator<Node> {
        public int compare(Node a, Node b){
            return a.distance_to_target < b.distance_to_target ? -1 : 1;
        }
    }


    /*
     * Class to get a target node's new class name from the give
     * top_k_neighbor array. The size of this array should be k.
     * All neighbors in this array do the majority vote.
     * The most common class among the neighbors becomes the new
     * class name for the target node.
     * If two classes' votes are the same, we go by the alphabet order.
     * Example:
     * In our case, our labels are [clear, clouds, rain].
     * So if clear gets 4 votes and clouds gets 4 votes,
     * the new class name will be clear.
     * 
     * @param Node node: the target node.
     * @param Node[] top_k_neighbor_arr: the target node's top k neighbors.
     * 
     * @return none
     */
    public static void getNodeNewClassByTopKNeighbors(Node node, Node[] top_k_neighbor_arr){
        // for(Node n: top_k_neighbor_arr){
        //     System.out.println(n);
        // }

        HashMap<String, Integer> count = new HashMap<String, Integer>();

        for(int i = 0; i < top_k_neighbor_arr.length; i ++){
            String classname = top_k_neighbor_arr[i].getClassName();

            if(count.containsKey(classname)){
                count.put(classname, count.get(classname) + 1);
            }
            else{
                count.put(classname, 1);
            }
        }

        TreeMap<String, Integer> sortedCount = new TreeMap<String, Integer>();
        sortedCount.putAll(count);
        // for(java.util.Map.Entry<String, Integer> pair: sortedCount.entrySet()){
        //     System.out.print(pair.getKey() + " " + pair.getValue() + ", ");
        // }
        // System.out.println();

        // Get max-vote. If votes are equal, use alphabet-order
        int max_vote = 0;
        String max_vote_class_name = "";
        for(java.util.Map.Entry<String, Integer> pair: sortedCount.entrySet()){
            if(pair.getValue() > max_vote){
                max_vote = pair.getValue();
                max_vote_class_name = pair.getKey();
            }
        }

        // System.out.println(max_vote + " " + max_vote_class_name);
        node.setNewClassName(max_vote_class_name);
    }

    /*
     * Helper function to get current timestamp
     */
    static public String getCurrentTimestamp(){
        return (new Timestamp(System.currentTimeMillis())).toString();
    }


    static public void main(String[] args) throws MPIException, IOException{
        // Start MPI
        MPI.Init(args);
        int rank = MPI.COMM_WORLD.Rank();
        int size = MPI.COMM_WORLD.Size();
        // Read all args
        // Validate args length
        if(args.length < 3){
            if(rank == Global.MASTER){
                System.err.println("Usage: mpirun -n <node#> java knnJavaMPI_v2 <input_test_group_file> <input_train_group_file> <top_k> <optional: output_info>");
                System.err.println("top_K: an integer. output_info: 1 or 0 (default), if 1 is entered, all information will be display while running.");
            }
            MPI.Finalize();
            System.exit(-1);
        }

        /* Init */
        // Get args
        int k = Integer.parseInt(args[2]);
        if(args.length > 3){
            if(Integer.parseInt(args[3]) > 0){
                Global.PRINT_INFO = true;
            }
        }

        // Input file for two groups of nodes
        File input_file_test = null;
        File input_file_train = null;
        // Scanner to read file
        Scanner sc_test = null;
        Scanner sc_train = null;

        Integer total_train_nodes = 0;
        Integer total_test_nodes = 0;
        // Array to store all train nodes
        Node[] train_group;
        // Array to store all test nodes
        Node[] test_group;
        // 2D array to store top-k neighbors for each target node found locally
        Node[][] top_k_local_arr;

        // The chunk size, to seperate data to slaves
        int chunk_size = 0;

        // Timer
        long start_time_all = System.currentTimeMillis();
        long start_time_read_file = System.currentTimeMillis();


        // Rank 0 reads file
        try{
            if(rank == 0){
                // Read test group
                input_file_test = new File(args[0]);
                sc_test = new Scanner(input_file_test);
                total_test_nodes = sc_test.nextInt();
                sc_test.nextLine();
                
                // Read train group
                input_file_train = new File(args[1]);
                sc_train = new Scanner(input_file_train);
                total_train_nodes = sc_train.nextInt();
                sc_train.nextLine();
                
                // Calculate chunk size
                chunk_size = total_train_nodes / size;

                if(Global.PRINT_INFO){
                    System.out.println("[" + getCurrentTimestamp() + "] " + "Rank(" + rank + ") read from file: " + "Total test nodes: " + total_test_nodes);
                    System.out.println("[" + getCurrentTimestamp() + "] " + "Rank(" + rank + ") read from file: " + "Total train nodes: " + total_train_nodes);
                }
            }
        }
        catch(FileNotFoundException e){
            System.err.println("Cannot open input file: " + e);
            MPI.Finalize();
            System.exit(-1);
        }

        // Mater send size info to slaves
        if(rank == 0){
            // MPI Java only send array-like object!!!
            // Convert an int to a int[1]!!!
            int[] mpi_total_train_nodes = new int[1];
            mpi_total_train_nodes[0] = total_train_nodes;
            int[] mpi_total_test_nodes = new int[1];
            mpi_total_test_nodes[0] = total_test_nodes;
            int[] mpi_chunk_size = new int[1];
            mpi_chunk_size[0] = chunk_size;

            // Send train_group size
            for(int i = 1; i < size; i ++){
                MPI.COMM_WORLD.Isend(
                    mpi_total_train_nodes,
                    0,
                    1,
                    MPI.INT,
                    i,
                    Global.MPI_TAG_SEND_TRAIN_GROUP_SIZE
                );
                // Send test_group size
                MPI.COMM_WORLD.Isend(
                    mpi_total_test_nodes,
                    0,
                    1,
                    MPI.INT,
                    i,
                    Global.MPI_TAG_SEND_TEST_GROUP_SIZE
                );
                // Send chunk size
                MPI.COMM_WORLD.Isend(
                    mpi_chunk_size,
                    0,
                    1,
                    MPI.INT,
                    i,
                    Global.MPI_TAG_SEND_CHUNK_SIZE
                );

                if(Global.PRINT_INFO){
                    System.out.println("[" + getCurrentTimestamp() + "] " + "Rank(" + rank + ") sent size info to " + "rank(" + i + ")");
                }
            }
        }
        // Slaves receive size info from Master
        else{
            // MPI Java :( 
            int[] mpi_total_train_nodes = new int [1];
            int[] mpi_total_test_nodes = new int [1];
            int[] mpi_chunk_size = new int[1];

            // Receive train_group size
            MPI.COMM_WORLD.Recv(
                mpi_total_train_nodes,
                0,
                1,
                MPI.INT,
                0,
                Global.MPI_TAG_SEND_TRAIN_GROUP_SIZE
            );
            // Receive test_group size
            MPI.COMM_WORLD.Recv(
                mpi_total_test_nodes,
                0,
                1,
                MPI.INT,
                0,
                Global.MPI_TAG_SEND_TEST_GROUP_SIZE
            );
            // Receive chunk size
            MPI.COMM_WORLD.Recv(
                mpi_chunk_size,
                0,
                1,
                MPI.INT,
                0,
                Global.MPI_TAG_SEND_CHUNK_SIZE
            );

            // Store the index-0 value of each array to where they should be :(
            total_train_nodes = mpi_total_train_nodes[0];
            total_test_nodes = mpi_total_test_nodes[0];
            chunk_size = mpi_chunk_size[0];

            if(Global.PRINT_INFO){
                System.out.println("[" + getCurrentTimestamp() + "] " + "Rank(" + rank + ") received group size info from Master.");
            }
        }

        if(Global.PRINT_INFO){
            if(rank != Global.MASTER){
                System.out.println("[" + getCurrentTimestamp() + "] " +"Rank(" + rank + ") display all size info: #TestNode: " + total_test_nodes + ", #TrainNode: " + total_train_nodes + ", chunkSize: " + chunk_size);
            }
            else{
                System.out.println("[" + getCurrentTimestamp() + "] " +"Rank(" + rank + ") display all size info: #TestNode: " + total_test_nodes + ", #TrainNode: " + total_train_nodes + ", chunkSize: " + (total_train_nodes - (size - 1) * chunk_size));
            }
        }
        
        /* Init some arrays based on the size read */
        // Allocate array to store train_group and test_group
        train_group = new Node[total_train_nodes];
        test_group = new Node[total_test_nodes];
        // Init top_k_gather_arr, used in the Master only
        // To store all top_k info from slaves
        ArrayList<ArrayList<Node>> top_k_gather_arr = new ArrayList<ArrayList<Node>>();
        for(int i = 0; i < total_test_nodes; i ++){
            top_k_gather_arr.add(new ArrayList<Node>());
        }
        // Allocate array to store top_k-neighbors for each target (test) node found locally
        // Used in slaves only, master will store in the gather_arr directly
        top_k_local_arr = new Node[total_test_nodes][k];
        
        
        /* Master begin read all data from input files */
        if (rank == 0){
            // Continue read test file
            int test_node_count = 0;
            try{
                while(sc_test.hasNextLine()){
                    String[] line = sc_test.nextLine().split(",", -1);
                    Node node = new Node(Double.parseDouble(line[0]), Double.parseDouble(line[1]), Double.parseDouble(line[2]), line[3]);
                    test_group[test_node_count ++] = node;
                }
            }
            catch(Exception e){
                System.err.println("Error while reading test file: " + e);
                MPI.Finalize();
                System.exit(-1);
            }

            // Continue read train file
            try{
                int train_node_count = 0;
                while(sc_train.hasNextLine()){
                    String[] line = sc_train.nextLine().split(",", -1);
                    Node node = new Node(Double.parseDouble(line[0]), Double.parseDouble(line[1]), Double.parseDouble(line[2]), line[3]);
                    train_group[train_node_count ++] = node;
                }
            }
            catch(Exception e){
                System.err.println("Error while reading train file: " + e);
                MPI.Finalize();
                System.exit(-1);
            }

            // Distribute data to slaves
            for(int i = 1; i < size; i ++){
                // Send test nodes to all slaves
                MPI.COMM_WORLD.Isend(
                    test_group,
                    0,
                    total_test_nodes,
                    MPI.OBJECT,
                    i,
                    Global.MPI_TAG_SEND_TEST_GROUP
                );

                // Send portion of train nodes to all slaves
                MPI.COMM_WORLD.Isend(
                    train_group,
                    chunk_size * (i - 1),
                    chunk_size,
                    MPI.OBJECT,
                    i,
                    Global.MPI_TAG_SEND_TRAIN_GROUP
                );

                if(Global.PRINT_INFO){
                    System.out.println("[" + getCurrentTimestamp() + "] " + "Rank(" + rank + ") sent nodes data to rank(" + i + ")");
                }
            }
        }
        // Other ranks receive from master
        else{
            // Receive test_group
            MPI.COMM_WORLD.Recv(
                test_group,
                0,
                total_test_nodes,
                MPI.OBJECT,
                0,
                Global.MPI_TAG_SEND_TEST_GROUP
            );
            // Receive portion of train_nodes
            MPI.COMM_WORLD.Recv(
                train_group,
                chunk_size * (rank - 1),
                chunk_size,
                MPI.OBJECT,
                0,
                Global.MPI_TAG_SEND_TRAIN_GROUP
            );

            if(Global.PRINT_INFO){
                System.out.println("[" + getCurrentTimestamp() + "] " + "Rank(" + rank + ") received nodes data from Master");
            }
        }

        // Stop the reading file timer
        long end_time_read_file = System.currentTimeMillis();

        
        /* Each rank now start KNN on each portion of train_group */
        // Start KNN timer
        long start_time_knn = System.currentTimeMillis();

        // Set this rank's start and end index of train_group
        int start = 0, end = 0;
        if(rank == Global.MASTER){
            start = chunk_size * (size - 1);
            end = total_train_nodes;
        }
        else{
            start = chunk_size * (rank - 1);
            end = chunk_size * rank;
        }
        
        // For each node in test group
        for(int i = 0; i < total_test_nodes; i ++){
            ArrayList<Node> temp = new ArrayList<Node>();
            // For each node in train group
            for(int j = start; j < end; j ++){
                // Get the train node's distance to target
                temp.add(new Node(train_group[j].x, train_group[j].y, train_group[j].z, train_group[j].className, distance(test_group[i], train_group[j])));
            }

            // After calculating is done for the current target node
            // Sort the train group by distance
            Collections.sort(temp,  Comparator.comparing(Node::getDistance));

            // Store the top k neighbors
            for(int z = 0; z < k; z ++){
                // Slaves store to local_arr, will send back to Master later
                if(rank != Global.MASTER){
                    top_k_local_arr[i][z] = temp.get(z);
                } 
                // Master store to the gather_arr directly
                else{
                    top_k_gather_arr.get(i).add(temp.get(z));
                }
            }
        }


        /* Each rank has done KNN */
        // Now everyone has get the top K for each target node in test group
        // Master receive each rank's top_k info back
        if(rank == Global.MASTER){
            for(int i = 1; i < size; i ++){
                Node[][] temp = new Node[total_test_nodes][k];
                MPI.COMM_WORLD.Recv(
                    temp,
                    0,
                    total_test_nodes,
                    MPI.OBJECT,
                    i,
                    Global.MPI_TAG_SEND_BACK_TOP_K
                );

                // Store received data
                for(int n = 0; n < total_test_nodes; n ++){
                    for(int m = 0; m < k; m ++){
                        top_k_gather_arr.get(n).add(temp[n][m]);
                    }
                }

                if(Global.PRINT_INFO){
                    System.out.println("[" + getCurrentTimestamp() + "] " + "Rank(" + rank + ") received top_k data from rank(" + i + ")");
                }
            }
        }
        // Slaves send local top_k info to Master
        else{
            MPI.COMM_WORLD.Send(
                top_k_local_arr,
                0,
                total_test_nodes,
                MPI.OBJECT,
                Global.MASTER,
                Global.MPI_TAG_SEND_BACK_TOP_K
            );

            if(Global.PRINT_INFO){
                System.out.println("[" + getCurrentTimestamp() + "] " + "Rank(" + rank + ") sent top_k data to Master");
            }
        }


        /* Finally */
        // Now Master received top_k info from all salves
        // If slaves# > 0, master should receive a total of 
        // slaves# * k of top_k_neighbors for each target node
        if(rank == 0){
            // For each target node
            for(int i = 0; i < total_test_nodes; i ++){
                // Sort this target node's top_k array
                Collections.sort(top_k_gather_arr.get(i),  Comparator.comparing(Node::getDistance));
                // Get the top_k among top_slaves#*k_k
                for(int j = 0; j < k; j ++){
                    top_k_local_arr[i][j] = top_k_gather_arr.get(i).get(j);
                }
            }

            // Now every target node found their top_k neighbors,
            // get everyone's new class name
            for(int i = 0; i < total_test_nodes; i ++){
                getNodeNewClassByTopKNeighbors(test_group[i], top_k_local_arr[i]);
            }

            // Stop KNN timer
            long end_time_knn = System.currentTimeMillis();

            // Calculate the correctness
            double acc = evaluateKnnCorrectness(test_group);

            // Stop main timer
            long end_time_all = System.currentTimeMillis();

            // Print all info
            System.out.println("Accuracy: " + acc);
            System.out.println("Elapsed time (Total) = " + (end_time_all - start_time_all));
            System.out.println("Elapsed time (Reading File & Data Passing) = " + (end_time_read_file - start_time_read_file));
            System.out.println("Elapsed time (KNN & Data Passing Back) = " + (end_time_knn - start_time_knn));
        }


        // MPI.COMM_WORLD.Barrier();
        MPI.Finalize();
    }
}